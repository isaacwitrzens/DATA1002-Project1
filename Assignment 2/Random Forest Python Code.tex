import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

train = pd.read_csv("train.csv")
valid = pd.read_csv("valid.csv")
test = pd.read_csv("test.csv")

target = "TotalCrimes"

X_train = train.drop(columns=[target])
y_train = train[target]

X_valid = valid.drop(columns=[target])
y_valid = valid[target]

X_test = test.drop(columns=[target])
y_test = test[target]


# Define parameter ranges

n_estimators_list = [100, 200]
max_depth_list = [5, None]
max_features_list = ["sqrt", None]
min_samples_split_list = [2, 5]

results = []


# Hyperparameter tuning

for n_estimators in n_estimators_list:
    for max_depth in max_depth_list:
        for max_features in max_features_list:
            for min_samples_split in min_samples_split_list:
                rf = RandomForestRegressor(
                    n_estimators=n_estimators,
                    max_depth=max_depth,
                    max_features=max_features,
                    min_samples_split=min_samples_split,
                    random_state=42,
                    n_jobs=-1
                )
                rf.fit(X_train, y_train)
                preds_valid = rf.predict(X_valid)

                r2 = r2_score(y_valid, preds_valid)
                mae = mean_absolute_error(y_valid, preds_valid)
                rmse = mean_squared_error(y_valid, preds_valid, squared=False)

                results.append({
                    "n_estimators": n_estimators,
                    "max_depth": max_depth,
                    "max_features": max_features,
                    "min_samples_split": min_samples_split,
                    "val_r2": r2,
                    "val_mae": mae,
                    "val_rmse": rmse
                })

# Store results
results_df = pd.DataFrame(results)

# Identify best parameters (highest R²)
best_row = results_df.loc[results_df["val_r2"].idxmax()]
best_params = {
    "n_estimators": int(best_row["n_estimators"]),
    "max_depth": None if pd.isna(best_row["max_depth"]) else best_row["max_depth"],
    "max_features": None if best_row["max_features"] == "None" else best_row["max_features"],
    "min_samples_split": int(best_row["min_samples_split"])
}

print("\nBest parameters (validation):", best_params)
print(best_row)


# Retrain on training data with best parameters

rf_best = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)
rf_best.fit(X_train, y_train)

preds_test = rf_best.predict(X_test)
test_r2 = r2_score(y_test, preds_test)
test_mae = mean_absolute_error(y_test, preds_test)
test_rmse = mean_squared_error(y_test, preds_test, squared=False)

print("\n=== Test performance ===")
print(f"R²:   {test_r2:.4f}")
print(f"MAE:  {test_mae:.2f}")
print(f"RMSE: {test_rmse:.2f}")